{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "HUsc15vGlzV2"
      },
      "source": [
        "# AI for Autonomous Robots: Embed your algorithm on an edge device - Practical Session\n",
        "\n",
        "## Introduction\n",
        "\n",
        "In this practical session you will implement the conversion of a PyTorch MobileNetv3 to the ONNX format.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lV4cqDbilubm",
        "outputId": "e5eeb564-50c4-4a14-f7cb-53e0891afb77"
      },
      "outputs": [],
      "source": [
        "# Install Dependencies\n",
        "!pip install onnx\n",
        "!pip install onnxruntime"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BEtLj6Ydrl_J"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m31-R9XRt931"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import models\n",
        "import cv2\n",
        "import numpy as np\n",
        "from torchsummary import summary\n",
        "import onnxruntime as ort\n",
        "import onnx\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SKz_Hzp3hTIT"
      },
      "source": [
        "## Create, print, and save a model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlD5QgwLuG5y",
        "outputId": "6e94d1b8-80aa-4ada-e5c4-f359e85a374b"
      },
      "outputs": [],
      "source": [
        "# create model\n",
        "model = models.mobilenet_v3_small(pretrained=True).cuda()\n",
        "model.eval()\n",
        "\n",
        "# print the model\n",
        "summary(model, (3, 224, 224))\n",
        "\n",
        "# save the model\n",
        "torch.save(model, 'mobilenet_v3.pth')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZBVwEqjhfEu"
      },
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "muaRPMb0vCov",
        "outputId": "e6d4c08e-a779-47f5-980e-80dbfb99eac6"
      },
      "outputs": [],
      "source": [
        "# load an image\n",
        "img_path = '/content/img.jpg'\n",
        "img = cv2.imread(img_path)\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# normalization\n",
        "img = cv2.resize(img, (224, 224))\n",
        "mean = np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
        "std = np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
        "img = np.array((img / 255.0 - mean) / std, dtype=np.float32)\n",
        "\n",
        "\n",
        "img = img.transpose([2, 0, 1])\n",
        "img_ = torch.from_numpy(img).unsqueeze(0).cuda()\n",
        "\n",
        "# prediction\n",
        "pred = model(img_)\n",
        "\n",
        "# sort \n",
        "_, indices = torch.sort(pred, descending=True)\n",
        "original_percentage = torch.nn.functional.softmax(pred, dim=1)[0] * 100\n",
        "print([\"prediction: {}, probability:{};\".format(idx, original_percentage[idx].item()) for idx in indices[0][:3]])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2pyttYavhmMC"
      },
      "source": [
        "## Task1: model conversion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yK6ogBCwUKJ",
        "outputId": "62034b76-d031-4efb-bd9a-c6dfd78d7028"
      },
      "outputs": [],
      "source": [
        "# Task1: convert the model to the ONNX format using torch.onnx\n",
        "\n",
        "def to_onnx(model, f: str = None):\n",
        "  # write your function here\n",
        "  # official document https://pytorch.org/docs/stable/onnx.html#\n",
        "  # -------\n",
        "  \n",
        "  input_names = [ \"input1\" ]\n",
        "  output_names = [ \"output1\" ]\n",
        "\n",
        "  if f is None:\n",
        "    f = \"mobilenet_v3.onnx\"\n",
        "\n",
        "  torch.onnx.export(model, img_, f, verbose=True, input_names=input_names, output_names=output_names)\n",
        "  # -------\n",
        "  \n",
        "to_onnx(model)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3JmYHk4khz7F"
      },
      "source": [
        "## Task2: Infer the ONNX model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hs2zFgpFN2kk",
        "outputId": "dccc471d-7c4d-408f-e301-3388b3d53b7d"
      },
      "outputs": [],
      "source": [
        "# Task2: run the ONNX model using onnxruntime\n",
        "def run_onnx(onnx_model, img):\n",
        "  # write your function here\n",
        "  # you can also get hints from the official document\n",
        "  \n",
        "  # -------\n",
        "  ort_session = ort.InferenceSession(onnx_model)\n",
        "\n",
        "  outputs = ort_session.run(\n",
        "    None,\n",
        "    {\"input1\": img},\n",
        "  ) \n",
        "  # -------\n",
        "  return outputs\n",
        "\n",
        "def np_softmax(x):\n",
        "    exp_x = np.exp(x)\n",
        "    return exp_x/np.sum(exp_x)\n",
        "\n",
        "\n",
        "result = run_onnx('mobilenet_v3.onnx', img_.cpu().numpy())\n",
        "result = result[0]\n",
        "indices = (-result).argsort()[:1000]\n",
        "onnx_percentage = np_softmax(result) * 100\n",
        "print([\"onnx_percentage    : {}, probability:{};\".format(idx, onnx_percentage[0][idx].item()) for idx in indices[0][:3]])\n",
        "print([\"original prediction: {}, probability:{};\".format(idx, original_percentage[idx].item()) for idx in indices[0][:3]])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "inbgm8bUh8KC"
      },
      "source": [
        "## Task3\n",
        "Please include your answers in your reports."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krtpr5vVN497"
      },
      "outputs": [],
      "source": [
        "# Task3: Visualize the exported ONNX model using Netron https://netron.app/, and \n",
        "# 1. compare its architecture with the one we printed earlier.\n",
        "# 2. compare the sizes of the models.\n",
        "# Please write down your thoughts."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
